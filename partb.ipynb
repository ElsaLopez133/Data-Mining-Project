{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "import collections\n",
    "import auxiliary_functions\n",
    "import pprint\n",
    "import json\n",
    "import random\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10000, 13)\n",
      "Query:  ['nbedrooms=2', 'windows=15', 'price=46']\n",
      "Dataframe of query:    nrooms nbedrooms nbath   sm garden_sm floors gargae_sm price year windows  \\\n",
      "0    NaN         2   NaN  NaN       NaN    NaN       NaN    46  NaN      15   \n",
      "\n",
      "  dist_city doors  \n",
      "0       NaN   NaN  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data_house/database.csv\", sep = ',') \n",
    "column_names = data.columns\n",
    "n = len(data.columns)\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "\n",
    "# Generate a random query   \n",
    "m = random.randint(1,4)\n",
    "df = data.sample(n = m, axis = 'columns').sample()\n",
    "row = []\n",
    "df_fake_queries = pd.DataFrame(index = range(1), columns = column_names)\n",
    "df_fake_queries.drop(df_fake_queries.columns[df_fake_queries.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "\n",
    "for j in range(len(df.columns)):\n",
    "    row.append(''.join((str(df.columns[j]),'=',str(df.iloc[0][j]))))\n",
    "    df_fake_queries[str(df.columns[j])].iloc[0] = df.iloc[0][j]\n",
    "\n",
    "print('Query: ', row)\n",
    "print('Dataframe of query: ', df_fake_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nbedrooms price windows\n",
      "0         2    46      15\n"
     ]
    }
   ],
   "source": [
    "query = df_fake_queries.dropna(axis = 1)\n",
    "query_columns = query.columns\n",
    "query_values = query.values[0]\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to check if the query already exists in our query database\n",
    "queries =  pd.read_csv(\"./data_house/queries_to_use.csv\", sep = ',', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common rows between two DataFrames...\n",
      " Empty DataFrame\n",
      "Columns: [query_id, nrooms, nbedrooms, nbath, sm, garden_sm, floors, gargae_sm, price, year, windows, dist_city, doors]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "resData = queries.merge(df_fake_queries, how = 'inner' ,indicator=False)\n",
    "print(\"Common rows between two DataFrames...\\n\",resData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['nbedrooms',\n",
       "  'price',\n",
       "  'windows',\n",
       "  ('nbedrooms', 'price'),\n",
       "  ('nbedrooms', 'windows'),\n",
       "  ('price', 'windows'),\n",
       "  ('nbedrooms', 'price', 'windows')],\n",
       " 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb, length = auxiliary_functions.combination(query_columns)\n",
    "comb, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nbedrooms': [], 'price': [], 'windows': [], \"('nbedrooms', 'price')\": [], \"('nbedrooms', 'windows')\": [], \"('price', 'windows')\": [], \"('nbedrooms', 'price', 'windows')\": []}\n"
     ]
    }
   ],
   "source": [
    "dict_query = {}\n",
    "# We create a dictionary with the possible combinations:\n",
    "comb, l = auxiliary_functions.combination(query_columns)\n",
    "for i in range(l):\n",
    "    dict_query.update({str(comb[i]) : []} )\n",
    "print(dict_query)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 3: up to 3 common value\n",
      "Dictionary:  {'nbedrooms': [8, 27, 42, 46, 50, 55, 80, 104, 122, 130, 145, 147, 151, 161, 165, 176, 188, 202, 275, 280, 329, 347, 352, 365, 373, 389, 412, 436, 441, 452, 473, 474, 485, 498, 555, 576, 582, 589, 598, 639, 648, 657, 659, 665, 666, 674, 699, 703, 705, 711, 714, 720, 741, 742, 751, 753, 760, 761, 766, 775, 777, 778, 792, 819, 834, 847, 851, 886, 887, 898, 929, 955, 962, 968, 974, 985, 1002, 1017, 1021, 1028, 1029, 1061, 1145, 1162, 1183, 1191, 1194, 1203, 1237, 1240, 1249, 1278, 1314, 1357, 1362, 1383, 1386, 1387, 1401, 1432, 1438, 1443, 1455, 1466, 1495, 1517, 1535, 1543, 1547, 1551, 1553, 1569, 1593, 1596, 1599, 1604, 1622, 1654, 1671, 1678, 1709, 1715, 1731, 1733, 1741, 1763, 1768, 1771, 1774, 1781, 1782, 1783, 1804, 1828, 1846, 1877, 1893, 1911, 1949, 1991, 1994, 1995], 'price': [530, 851, 1068, 1253, 1477, 1640, 1934], 'windows': [33, 218, 332, 380, 391, 397, 603, 839, 943, 1033, 1617, 1769, 1850, 1863, 1895], \"('nbedrooms', 'price')\": [851], \"('nbedrooms', 'windows')\": [], \"('price', 'windows')\": [], \"('nbedrooms', 'price', 'windows')\": [], \"('nbedrooms', 'nbedrooms')\": [8, 27, 42, 46, 50, 55, 80, 104, 122, 130, 145, 147, 151, 161, 165, 176, 188, 202, 275, 280, 329, 347, 352, 365, 373, 389, 412, 436, 441, 452, 473, 474, 485, 498, 555, 576, 582, 589, 598, 639, 648, 657, 659, 665, 666, 674, 699, 703, 705, 711, 714, 720, 741, 742, 751, 753, 760, 761, 766, 775, 777, 778, 792, 819, 834, 847, 851, 886, 887, 898, 929, 955, 962, 968, 974, 985, 1002, 1017, 1021, 1028, 1029, 1061, 1145, 1162, 1183, 1191, 1194, 1203, 1237, 1240, 1249, 1278, 1314, 1357, 1362, 1383, 1386, 1387, 1401, 1432, 1438, 1443, 1455, 1466, 1495, 1517, 1535, 1543, 1547, 1551, 1553, 1569, 1593, 1596, 1599, 1604, 1622, 1654, 1671, 1678, 1709, 1715, 1731, 1733, 1741, 1763, 1768, 1771, 1774, 1781, 1782, 1783, 1804, 1828, 1846, 1877, 1893, 1911, 1949, 1991, 1994, 1995], \"('price', 'price')\": [530, 851, 1068, 1253, 1477, 1640, 1934], \"('windows', 'windows')\": [33, 218, 332, 380, 391, 397, 603, 839, 943, 1033, 1617, 1769, 1850, 1863, 1895]}\n"
     ]
    }
   ],
   "source": [
    "# We can look for queries that share some of the values\n",
    "# We create a dictionary to update the repeated values:\n",
    "length = len(query_columns)\n",
    "\n",
    "dict_query = auxiliary_functions.matching_queries(length, query_columns, query, dict_query, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d7fc9756e6d3d4b3fe7869fe2ad8d9e8627485ab5c06687c17be4604983b9ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
