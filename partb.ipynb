{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "import collections\n",
    "import auxiliary_functions\n",
    "import pprint\n",
    "import json\n",
    "import random\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10000, 13)\n",
      "Query:  ['garden_sm=8', 'floors=2', 'price=25', 'doors=10']\n",
      "Dataframe of query:    nrooms nbedrooms nbath   sm garden_sm floors gargae_sm price year windows  \\\n",
      "0    NaN       NaN   NaN  NaN         8      2       NaN    25  NaN     NaN   \n",
      "\n",
      "  dist_city doors  \n",
      "0       NaN    10  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data_house/database.csv\", sep = ',') \n",
    "column_names = data.columns\n",
    "n = len(data.columns)\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "\n",
    "# Generate a random query   \n",
    "m = random.randint(1,4)\n",
    "df = data.sample(n = m, axis = 'columns').sample()\n",
    "row = []\n",
    "df_fake_queries = pd.DataFrame(index = range(1), columns = column_names)\n",
    "df_fake_queries.drop(df_fake_queries.columns[df_fake_queries.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "\n",
    "for j in range(len(df.columns)):\n",
    "    row.append(''.join((str(df.columns[j]),'=',str(df.iloc[0][j]))))\n",
    "    df_fake_queries[str(df.columns[j])].iloc[0] = df.iloc[0][j]\n",
    "\n",
    "print('Query: ', row)\n",
    "print('Dataframe of query: ', df_fake_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  garden_sm floors price doors\n",
      "0         8      2    25    10\n"
     ]
    }
   ],
   "source": [
    "query = df_fake_queries.dropna(axis = 1)\n",
    "query_columns = query.columns\n",
    "query_values = query.values[0]\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to check if the query already exists in our query database\n",
    "queries =  pd.read_csv(\"./data_house/queries_to_use.csv\", sep = ',', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common rows between two DataFrames...\n",
      " Empty DataFrame\n",
      "Columns: [query_id, nrooms, nbedrooms, nbath, sm, garden_sm, floors, gargae_sm, price, year, windows, dist_city, doors]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "resData = queries.merge(df_fake_queries, how = 'inner' ,indicator=False)\n",
    "print(\"Common rows between two DataFrames...\\n\",resData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['garden_sm',\n",
       "  'floors',\n",
       "  'price',\n",
       "  'doors',\n",
       "  ('garden_sm', 'floors'),\n",
       "  ('garden_sm', 'price'),\n",
       "  ('garden_sm', 'doors'),\n",
       "  ('floors', 'price'),\n",
       "  ('floors', 'doors'),\n",
       "  ('price', 'doors'),\n",
       "  ('garden_sm', 'floors', 'price'),\n",
       "  ('garden_sm', 'floors', 'doors'),\n",
       "  ('garden_sm', 'price', 'doors'),\n",
       "  ('floors', 'price', 'doors'),\n",
       "  ('garden_sm', 'floors', 'price', 'doors')],\n",
       " 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb, length = auxiliary_functions.combination(query_columns)\n",
    "comb, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'garden_sm': [], 'floors': [], 'price': [], 'doors': [], \"('garden_sm', 'floors')\": [], \"('garden_sm', 'price')\": [], \"('garden_sm', 'doors')\": [], \"('floors', 'price')\": [], \"('floors', 'doors')\": [], \"('price', 'doors')\": [], \"('garden_sm', 'floors', 'price')\": [], \"('garden_sm', 'floors', 'doors')\": [], \"('garden_sm', 'price', 'doors')\": [], \"('floors', 'price', 'doors')\": [], \"('garden_sm', 'floors', 'price', 'doors')\": []}\n"
     ]
    }
   ],
   "source": [
    "dict_query = {}\n",
    "# We create a dictionary with the possible combinations:\n",
    "comb, l = auxiliary_functions.combination(query_columns)\n",
    "for i in range(l):\n",
    "    dict_query.update({str(comb[i]) : []} )\n",
    "print(dict_query)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 4: up to 4 common value\n",
      "Dictionary:  {'garden_sm': [47, 76, 122, 138, 169, 172, 175, 190, 218, 284, 318, 358, 374, 383, 396, 550, 569, 737, 991, 1027, 1110, 1113, 1132, 1166, 1252, 1357, 1449, 1562, 1574, 1604, 1646, 1787, 1854, 1920, 1991], 'floors': [1, 20, 65, 66, 67, 68, 71, 104, 111, 150, 155, 159, 173, 182, 212, 218, 227, 233, 243, 254, 255, 297, 310, 312, 315, 336, 338, 349, 363, 368, 371, 390, 406, 413, 417, 429, 431, 462, 478, 483, 502, 506, 512, 554, 559, 578, 591, 599, 614, 617, 632, 637, 676, 683, 715, 735, 739, 743, 775, 781, 802, 830, 842, 850, 855, 866, 883, 895, 901, 902, 917, 946, 952, 954, 961, 1012, 1014, 1020, 1026, 1037, 1044, 1071, 1095, 1098, 1123, 1132, 1146, 1163, 1179, 1226, 1241, 1267, 1278, 1288, 1305, 1319, 1329, 1346, 1349, 1365, 1403, 1420, 1421, 1423, 1444, 1446, 1449, 1456, 1508, 1539, 1542, 1545, 1548, 1562, 1567, 1580, 1599, 1612, 1621, 1622, 1684, 1701, 1740, 1749, 1772, 1775, 1799, 1809, 1810, 1812, 1861, 1865, 1883, 1901, 1913, 1946, 1949, 1978, 1984], 'price': [1006, 1017, 1694, 1743], 'doors': [16, 84, 133, 174, 232, 321, 336, 388, 415, 425, 426, 439, 607, 631, 684, 687, 705, 739, 784, 809, 930, 950, 1026, 1032, 1182, 1191, 1193, 1204, 1212, 1220, 1374, 1396, 1416, 1418, 1437, 1464, 1566, 1586, 1618, 1793, 1827, 1837, 1855, 1860, 1862, 1911], \"('garden_sm', 'floors')\": [218, 1132, 1449, 1562], \"('garden_sm', 'price')\": [], \"('garden_sm', 'doors')\": [], \"('floors', 'price')\": [], \"('floors', 'doors')\": [336, 739, 1026], \"('price', 'doors')\": [], \"('garden_sm', 'floors', 'price')\": [218, 1132, 1449, 1562], \"('garden_sm', 'floors', 'doors')\": [218, 1132, 1449, 1562], \"('garden_sm', 'price', 'doors')\": [], \"('floors', 'price', 'doors')\": [], \"('garden_sm', 'floors', 'price', 'doors')\": []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elsal\\OneDrive\\Documentos\\Master\\EIT\\Trento\\DataMining\\project\\auxiliary_functions.py:258: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  idx = list(queries[queries[str(query_columns[j])] == query.iloc[0,j]][queries[str(query_columns[i])] == query.iloc[0,i]].index)\n",
      "c:\\Users\\elsal\\OneDrive\\Documentos\\Master\\EIT\\Trento\\DataMining\\project\\auxiliary_functions.py:265: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  idx = list(queries[queries[str(query_columns[j])] == query.iloc[0,j]][queries[str(query_columns[i])] == query.iloc[0,i]][queries[queries[str(query_columns[k])] == query.iloc[0,k]]].index)\n",
      "c:\\Users\\elsal\\OneDrive\\Documentos\\Master\\EIT\\Trento\\DataMining\\project\\auxiliary_functions.py:270: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  idx = list(queries[queries[str(query_columns[0])] == query.iloc[0,0]][queries[str(query_columns[1])] == query.iloc[0,1]][queries[str(query_columns[2])] == query.iloc[0,2]][queries[str(query_columns[3])] == query.iloc[0,3]].index)\n"
     ]
    }
   ],
   "source": [
    "# We can look for queries that share some of the values\n",
    "# We create a dictionary to update the repeated values:\n",
    "length = len(query_columns)\n",
    "\n",
    "dict_query = auxiliary_functions.matching_queries(length, query_columns, query, dict_query, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d7fc9756e6d3d4b3fe7869fe2ad8d9e8627485ab5c06687c17be4604983b9ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
